\documentclass[a4paper, 11pt]{article}
\usepackage[margin=0.8in]{geometry}
%\usepackage[T1]{fontenc}
%\usepackage{babel}
%\setcounter{section}{6}
\setlength{\tabcolsep}{8pt}
\renewcommand{\arraystretch}{1.5}
\usepackage{url}

\author{
  Babbar, Abhimanyu\\
  \textsc{890729-7751}\\
  \texttt{babbar@kth.se}
}
\title{Network Partition Scenarios} 

\begin{document}

\maketitle 

\section{Scenarios}
Analysis of the different Network Partition Scenarios and there potential solutions.

\subsection{Very Short Lived Partition}
The basic and a very frequent scenario that would occur would be that for a very short duration of time, a set of nodes gets networked partitioned. The duration is small enough so that the nodes that got partitioned \textbf{are unable to elect a new leader}.\\

\textbf{Solution}: The nodes simply merge back without any hiccups and start working as before and fetch the entries if any that could have been added in that short duration.


\subsection{Short Lived Partition}
A scenario in which the nodes partition in separate branches and diverge from a common point. The stale descriptors for some time will be present in the gradient and might be buffered in the communication maps of the application. In this, it might be possible that the other partition moves ahead and its leader unit history evolves but the partition heals before the application in the other branch is able to clean the partitioned nodes. \\

\textbf{Solution}: The solution for this case will be tricky because the nodes will still contain stale samples from other nodes in the system and in case the partition heals without the samples being removed from the node the node will contact with the nodes. Therefore more tight control needs to be imposed on every message exchange in terms of introducing last leader unit in every exchange to prevent them to serve the data which does not belong to the current network partition. It will pollute the partition.

\subsection{Medium Lived Partition without External Intervention}
Scenario in which the nodes partition in separate branches but the time for which the nodes partition is large enough so that the samples became stale enough to be removed from the gradient. As gradient implements an age threshold mechanism which simply removes all the samples from the gradient which are above a certain age. In addition to this, we assume that the stale samples are present in croupier and therefore when the partition merges back in the croupier component communicates with the samples and when response is received, the samples start getting pushed to the gradient with low ages. The gradient then filters these samples and inform application about the partitioned nodes.

\subsection{Medium Lived Partitioned With 3rd Party Intervention}
In this scenario, \textit{caracal} is used as an arbitrator and nodes constantly ping the caracal for checking for the network partition. The system when getting network partitioned, one branch of the partitioned is unable to ping the caracal and detect it as a network partition. When assume that the stale descriptors are removed from application, gradient and croupier. Therefore on partition merge, the croupier needs to be bootstrapped with the nodes from other partition and this is place where caracal is useful as it provides the nodes from the other partition on heartbeat response or separately when asked explicitly.



\subsection{General Network Partition Without Sharding}
The main case that needs to be handled as part of thesis scope is that nodes gets networked partitioned for a medium to long duration of time but the partition heals before any set of nodes reaches the sharding stage. The set of nodes act independently and the nodes which got separated from the leader, thinks that the leader is dead and therefore elects a new leader. Both the partitions keep moving forwards and there histories keep on evolving in terms of container switches. In the current scenario, there are several cases that can arise and need to be handled.\\


But before we can visit the different cases, we need to look at solution that would be used to resolve the case of network partitioning. \\

\textbf{General Solution}: The descriptor that contains a subset of information about the nodes is exchanged by the nodes with others in the system. The information needs to be augmented with the \textit{Last Leader Unit} that the node has seen when exchanging the information in the system. This information will be used by the other node to check if the unit is contained in the \textit{ History} which is the sorted list of the unit updates that has been seen by that particular node. Every node maintains a local history of the leader unit updates. 

In case the leader unit is not found in the history, the node is marked as a suspected node and handed over to the application for further investigation. The case of finding a node in the leader history also needs to be expanded. Below are cases that could occur between the exchange between nodes A and B.


\begin{enumerate}

\item Both nodes have same last leader unit in there respective histories. 

\item One of the nodes is ahead in the history and the other node's last leader unit is present in the history of the former one.

\item One of the nodes is ahead in the history but it does not contain the leader unit provided by the other node in its local history.

\end{enumerate}


The steps that the node will take will vary based on the scenario that the node is operating under.\\


\textbf{General Shuffle Scenario}: Let us assume there are two nodes A and B in the system. As part of periodic shuffle round, node A wakes up and generates its own descriptor based on the latest information available to the \textit{Partition Aware Gradient}. The node picks up a node to shuffle with based on its utility. The gradient component simply sends the shuffle request to the node. The message is then intercepted by the Partition Aware Gradient Component and this component decides whether to send the request forward or not:


The partition aware gradient looks at the \textit{last leader unit} of the node in the request. Now two cases could arise :

\begin{enumerate}

\item Either the node is present in the history of the sending node and therefore the request is allowed to pass through.

\item The node is unable to find the node's last leader unit in the history and thus puts the node in the suspected list and hands over the list to the application for further investigation. (This task could also be performed by the component itself but depends upon the data needs to be accessed for investigation.)


\end{enumerate}


\textbf{Questions}: Some questions based on the above scenario:

\begin{enumerate}



\item Is there a node that is truly ahead of another node ?

\textbf{Ans)} The last leader unit that the node is at helps to determine if a node is ahead of another node but due to network partition merge there might be cases in which the nodes that are rising in the system are at the same epoch in terms of last leader units but having different leader id's in the leader unit.



\item What happens if the Last Leader Unit of the descriptor that the node is trying to shuffle with is ahead of the node's self last leader unit ?

\textbf{Ans)} It might be that the node be lagging behind on the updates and therefore haven't seen them yet or might be a case of network partition merge. So, I think it means that the \textit{Partition Aware Gradient} should only allow the nodes whose last leader unit is a subset of it's own history and in all the other cases should send it to the application for inspection. ( \textbf{ Not sure on this one } )




\item How does the Partition Aware Gradient decides what to block and what to allow (\textit{information from the request/ response and the croupier data push}) ?

\textbf{Ans)} The PAG needs to exert a tight control over the message exchange as part of Gradient shuffle and also the data coming from the croupier. The messages need to be intercepted and then the descriptor is analyzed by the PAG. In case a suspicious descriptor is found, the application is informed about the unverified node which can be a potential partition merge and therefore the PAG currently blocks it and waits for the application to come back to it about the nature of the unit update. 


\item Can the PAG direct the gradient to remove a particular sample from the Gradient ?

\textbf{Ans)} What happens to the sample in the gradient that the PAG refuses to shuffle with and drops the message. Can the PAG direct the gradient also to remove the node descriptor so that the gradient should not spread the sample to other nodes in the system ?

\item How does the case of the Sharding differs from the case of partition merge in which the nodes from one branch are at the same level and the nodes in other branch have moved forward in terms of container switches and then the partition heals ?

\textbf{Ans)} \textit{ Not sure on how to resolve this one }. Just one thing that comes to mind is that the application components of the nodes should have bulk of responsibility of deciding the nodes or better yet the leader units that are safe to shuffle with. In addition to this, the PAG check needs to be applied both at the request and the response phase of the protocol.

\item What are the steps that the Application needs to take ?

\textbf{Ans)} Once the application receives the suspected list from the Partition Aware Gradient (PAG), the application needs to determine that the node is not from other partition and it is not a case of Partition Merge. The application initiates a verification mechanism in which based on the current last leader unit, sends a verification request to the node about the last leader unit, in sense that it asks the node that : \textit{ Hey I am not able to determine whether to shuffle with you or not as you are ahead, so do you see me in your history ?}

In addition to this, what needs to happen in case the last leader unit of the node provided by the PAG is behind the current last leader unit and not in the history ?

It can be a false positive as there might be a network partition merge going on and the node is a new node which has fetched the unit update from a node that has already received the partition merge update and incorporated the new units in its history. How does the application determine it's a case of false detection of partition merge. The leader intervention is required in this case ? ( \textit{ Does the node route the query upwards towards the leader with a predefined TTL ? } )

\end{enumerate}



\section{Special Cases}


\subsection{Split Point Case} A very common scenario that could occur as part of Network Partitioning is that one of the partitioned branches (Ones that don't have the leader at which the partition occurs ), thinks that the leader is dead and therefore close the leader unit at the max entries based on the entries present in the new leader. The other branch could very well be continuing with the same leader unit and adding more entries in that unit and therefore  we have a unique case in which \textit{histories of both leader units} will contain the same leader unit but with different entries.

In case the partition heals at the point at which the common leader unit is still on going in one of the leader units, this need to be handled correctly because the nodes when asking the last leader unit from the other nodes, they will have the unit in the history but the entries in that unit will be different. This can create issues in terms of entries being pulled by a particular node. \\

\textbf{Solution}: The solution to this should be that there needs to be a checking between the current tracking id and the max entries of the leader unit being tracked. The node should always ask for the entries up-to a maximum point in the request in the closing update has been received for the leader unit. 

\subsection{Buffered Leader Unit} The case of buffered leader units is kind of tricky to understand. It is important to fully understand the premise because we need to solve it correctly. A node in the system usually buffers the updates when he is lagging in the leader unit pull in a current partition. In this case it might be possible that the node becomes a part of leader group due to churn. Therefore we might see jumps in the leader unit history which leads to the buffering of updates. A node which is simply lagging behind and pulling the updates from the nodes nearby will always get the updates in order and therefore the case of buffered updates will not occur.

In case the updates being pulled through the control mechanism fill a jump, we need to check for the next epoch updates from buffered ones and therefore apply them in order. It is because the buffered updates are important and needed as these updates might be necessary for the nodes in the current partition as the nodes that buffered them might be the only ones except leader to add them and therefore it is necessary to keep them buffered. \textit { They are necessary for the liveness condition of the system. }

While adding the buffered updates we must take care of the sharding update and empty the buffered unit list when the sharding update is successfully processed by the system. Because the nodes are concerned about the current shard and if they have buffered entries from shard ahead, it means that data is already replicated in the shard and therefore we can again pull once we have sharded. 


\subsection{Partition Aware Gradient}
The PAG needs to be constructed carefully as there might be a lot of cases in which can result in inconsistent state. Some of the considerations are as follows:

\begin{enumerate}

\item The node needs to keep a buffered list of verified and suspected nodes. The list should always be cleared when a new last leader unit is received because the node which might be a current extension based on latest leader unit, might not be for the next leader unit switch and therefore needs to be taken care of by completely emptying the verfied list. Suspected ones need not to be cleared as the node always move forward in the system and if a current node is not a logical extension then it is very likely that it will not be later onewards also.



\end{enumerate}


\end{document}